{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deck_creator import AnkiDeckCreator, correct_translation_order, shuffle_list\n",
    "deck_id = 2059400110\n",
    "model_id = 1607392319\n",
    "deck_name = 'MyDeck'\n",
    "anki_phrases = correct_translation_order(anki_phrases)\n",
    "anki_phrases = shuffle_list(anki_phrases)\n",
    "deck_creator = AnkiDeckCreator(deck_name, deck_id, model_id)\n",
    "deck_creator.generate_deck(anki_phrases)\n",
    "deck_creator.create_package('cuidar.apkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deck_creator import AnkiDeckCreator, correct_translation_order, shuffle_list\n",
    "\n",
    "deck_id = 2059400111\n",
    "model_id = 1607392320\n",
    "deck_name = 'questions'\n",
    "anki_phrases = correct_translation_order(anki_phrases)\n",
    "anki_phrases = shuffle_list(anki_phrases)\n",
    "deck_creator = AnkiDeckCreator(deck_name, deck_id, model_id)\n",
    "deck_creator.generate_deck(anki_phrases)\n",
    "deck_creator.create_package('questions1.apkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deck_creator import AnkiDeckCreator, correct_translation_order, shuffle_list\n",
    "\n",
    "deck_id = 2059400112\n",
    "model_id = 1607392321\n",
    "deck_name = 'ds'\n",
    "anki_phrases = shuffle_list(anki_phrases)\n",
    "deck_creator = AnkiDeckCreator(deck_name, deck_id, model_id)\n",
    "deck_creator.generate_deck(anki_phrases)\n",
    "deck_creator.create_package('questions_ds.apkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "fait = ['advice', 'aliens', 'animals', 'appearance', 'beauty', 'books', 'brains', 'cars and driving', 'challengers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "anki_phrases = [\n",
    "    {'front': 'O que é overfitting e como você pode evitar isso em modelos de aprendizado de máquina?', \n",
    "     'back': 'Overfitting ocorre quando um modelo se ajusta muito bem aos dados de treinamento, mas não generaliza bem para novos dados. Para evitar isso, podemos usar técnicas como validação cruzada, regularização e aumentar o tamanho do conjunto de dados.'},\n",
    "    \n",
    "    {'front': 'Explique a diferença entre validação cruzada e conjunto de treinamento/teste.', \n",
    "     'back': 'Conjunto de treinamento/teste divide os dados em dois conjuntos: um para treinar o modelo e outro para avaliá-lo. A validação cruzada é uma técnica para avaliar a capacidade de generalização de um modelo, dividindo os dados em várias partes e treinando/testando o modelo em diferentes combinações dessas partes.'},\n",
    "    \n",
    "    {'front': 'Qual é a diferença entre regressão e classificação?', \n",
    "     'back': 'Regressão é usada para prever valores contínuos, enquanto classificação é usada para prever classes ou categorias.'},\n",
    "    \n",
    "    {'front': 'Como você lida com dados ausentes em um conjunto de dados?', \n",
    "     'back': 'Podemos lidar com dados ausentes preenchendo-os com a média/mode dos valores existentes, excluindo as linhas com dados ausentes ou usando técnicas mais avançadas como imputação.'},\n",
    "    \n",
    "    {'front': 'Explique o conceito de normalização de dados e por que é importante.', \n",
    "     'back': 'Normalização de dados é o processo de ajustar os valores de uma variável para que fiquem em uma escala específica. Isso é importante porque muitos algoritmos de machine learning são sensíveis à escala dos dados.'},\n",
    "    \n",
    "    {'front': 'O que é seleção de recursos (feature selection) e por que é importante?', \n",
    "     'back': 'Seleção de recursos é o processo de escolher as variáveis mais importantes para o modelo. É importante porque pode melhorar a precisão do modelo, reduzir o tempo de treinamento e evitar overfitting.'},\n",
    "    \n",
    "    {'front': 'Descreva o processo de pré-processamento de dados.', \n",
    "     'back': 'Pré-processamento de dados envolve limpeza, transformação e preparação dos dados para análise. Isso pode incluir tratamento de dados ausentes, normalização, codificação de variáveis categóricas, entre outros.'},\n",
    "    \n",
    "    {'front': 'O que são algoritmos de aprendizado supervisionado e não supervisionado?', \n",
    "     'back': 'Algoritmos de aprendizado supervisionado usam dados rotulados para treinar modelos que podem fazer previsões ou classificações. Algoritmos de aprendizado não supervisionado exploram a estrutura dos dados sem orientação de rótulos.'},\n",
    "    \n",
    "    {'front': 'Como você avalia a performance de um modelo de machine learning?', \n",
    "     'back': 'A performance de um modelo pode ser avaliada usando métricas como precisão, recall, F1-score, matriz de confusão, curva ROC, entre outras, dependendo do tipo de problema e dos requisitos específicos.'},\n",
    "    \n",
    "    {'front': 'Explique a diferença entre bias e variância.', \n",
    "     'back': 'Bias refere-se ao erro sistemático de um modelo, enquanto variância refere-se à sensibilidade do modelo às flutuações nos dados de treinamento. O objetivo é encontrar um equilíbrio entre bias e variância para criar um modelo que generalize bem para novos dados.'},\n",
    "    \n",
    "    {'front': 'O que é uma matriz de confusão e como ela é usada?', \n",
    "     'back': 'Uma matriz de confusão é uma tabela que descreve o desempenho de um modelo de classificação. Ela mostra o número de verdadeiros positivos, falsos positivos, verdadeiros negativos e falsos negativos. É usada para calcular várias métricas de desempenho, como precisão, recall e F1-score.'},\n",
    "    \n",
    "    {'front': 'Como você escolhe o algoritmo certo para um problema específico?', \n",
    "     'back': 'A escolha do algoritmo depende do tipo de problema, do tamanho e da natureza dos dados, dos recursos computacionais disponíveis e de outras considerações. É importante experimentar diferentes algoritmos e ajustar seus hiperparâmetros para encontrar o melhor desempenho.'},\n",
    "    \n",
    "    {'front': 'O que é clustering e em que situações é útil?', \n",
    "     'back': 'Clustering é uma técnica de aprendizado não supervisionado que agrupa dados similares em clusters. É útil para explorar a estrutura dos dados, identificar padrões e segmentar os dados em grupos distintos.'},\n",
    "    \n",
    "    {'front': 'Como você lidaria com um conjunto de dados muito grande que não pode ser carregado na memória?', \n",
    "     'back': 'Podemos usar técnicas de amostragem, processamento em lote, armazenamento em disco e computação distribuída para lidar com conjuntos de dados grandes que não cabem na memória.'},\n",
    "    \n",
    "    {'front': 'O que é validação out-of-time (out-of-sample) e por que é importante?', \n",
    "     'back': 'Validação out-of-time envolve a criação de conjuntos de treinamento e teste que não incluem dados do mesmo período de tempo. Isso é importante para avaliar a capacidade de generalização de um modelo para novos dados não vistos.'},\n",
    "    \n",
    "    {'front': 'Descreva a diferença entre uma árvore de decisão e um random forest.', \n",
    "     'back': 'Uma árvore de decisão é um modelo de aprendizado de máquina que toma decisões com base em regras simples, enquanto um random forest é um conjunto de árvores de decisão que combina várias árvores para melhorar a precisão e reduzir o overfitting.'},\n",
    "    \n",
    "    {'front': 'Como você lidaria com dados desbalanceados?', \n",
    "     'back': 'Podemos lidar com dados desbalanceados usando técnicas como oversampling, undersampling, geração sintética de dados ou ajuste de pesos das classes durante o treinamento do modelo.'},\n",
    "    \n",
    "    {'front': 'O que é regularização em modelos de aprendizado de máquina?', \n",
    "     'back': 'Regularização é uma técnica usada para evitar overfitting em modelos de machine learning, adicionando uma penalidade aos pesos do modelo. Isso ajuda a simplificar o modelo, reduzindo a complexidade e melhorando a capacidade de generalização.'},\n",
    "    \n",
    "    {'front': 'Explique o conceito de gradient descent.', \n",
    "     'back': 'Gradient descent é um algoritmo de otimização usado para encontrar o mínimo de uma função. Ele funciona iterativamente atualizando os parâmetros do modelo na direção oposta do gradiente da função de custo.'},\n",
    "    \n",
    "    {'front': 'Como você interpretaria os resultados de um modelo de machine learning?', \n",
    "     'back': 'Os resultados de um modelo de machine learning podem ser interpretados usando métricas de desempenho, visualizações de dados, análise de erros e comparação com outros modelos. É importante entender o contexto do problema e as implicações práticas dos resultados.'},\n",
    "    \n",
    "    {'front': 'O que é o método k-fold cross-validation e como ele funciona?', \n",
    "     'back': 'O k-fold cross-validation é uma técnica de avaliação de modelo que divide o conjunto de dados em k partes iguais. O modelo é treinado k vezes, cada vez usando k-1 partes como dados de treinamento e a parte restante como dados de teste. Os resultados são então médios para produzir uma única estimativa de desempenho.'},\n",
    "    \n",
    "    {'front': 'Explique a diferença entre algoritmos de aprendizado supervisionado e não supervisionado.', \n",
    "     'back': 'Algoritmos de aprendizado supervisionado requerem dados rotulados para treinar o modelo, enquanto algoritmos de aprendizado não supervisionado exploram a estrutura dos dados sem rótulos.'},\n",
    "    \n",
    "    {'front': 'O que é o problema de classificação multiclasse e como você o abordaria?', \n",
    "     'back': 'O problema de classificação multiclasse envolve prever uma variável de saída que pode ter mais de duas classes. Pode ser abordado usando algoritmos como regressão logística multinomial, árvores de decisão ou SVMs (Support Vector Machines) com estratégias de um contra todos ou um contra um.'},\n",
    "    \n",
    "    {'front': 'Descreva a diferença entre regressão linear e regressão logística.', \n",
    "     'back': 'Regressão linear é usada para prever valores contínuos, enquanto regressão logística é usada para prever probabilidades associadas a duas ou mais classes.'},\n",
    "    \n",
    "    {'front': 'Como você escolheria o número ideal de clusters em um algoritmo de clustering?', \n",
    "     'back': 'Podemos usar técnicas como o método do cotovelo (elbow method), análise de silhueta (silhouette analysis) ou validação externa para determinar o número ideal de clusters.'},\n",
    "    \n",
    "    {'front': 'O que é o trade-off viés-variância e por que é importante?', \n",
    "     'back': 'O trade-off viés-variância é o equilíbrio entre o erro devido ao viés (bias) e o erro devido à variância. É importante porque modelar um fenômeno complexo pode resultar em um modelo com alta variância e baixo viés, ou vice-versa, e é necessário encontrar um equilíbrio para obter um modelo que generalize bem para novos dados.'},\n",
    "    \n",
    "    {'front': 'Como você trataria dados categóricos em um modelo de machine learning?', \n",
    "     'back': 'Dados categóricos podem ser tratados convertendo-os em variáveis dummy (one-hot encoding), codificação ordinal, ou usando técnicas mais avançadas como codificação de frequência ou target encoding.'},\n",
    "    \n",
    "    {'front': 'O que é a técnica de regularização Lasso e Ridge e em que situações você as usaria?', \n",
    "     'back': 'Lasso e Ridge são técnicas de regularização usadas para evitar overfitting em modelos de regressão, adicionando uma penalidade aos coeficientes dos parâmetros. Lasso utiliza uma penalidade L1, enquanto Ridge utiliza uma penalidade L2. Lasso é útil quando se deseja realizar seleção automática de características, enquanto Ridge é útil para reduzir a complexidade do modelo.'},\n",
    "    \n",
    "    {'front': 'Explique o conceito de bagging e boosting em modelos de ensemble.', \n",
    "     'back': 'Bagging e boosting são técnicas de ensemble usadas para combinar vários modelos fracos em um modelo forte. Bagging (bootstrap aggregating) treina vários modelos independentes em subconjuntos aleatórios dos dados e combina suas previsões por votação ou média. Boosting treina modelos sequencialmente, dando mais peso aos exemplos classificados incorretamente pelo modelo anterior.'},\n",
    "    \n",
    "    {'front': 'Como você lidaria com outliers em um conjunto de dados?', \n",
    "     'back': 'Outliers podem ser tratados removendo-os, transformando-os, ou usando métodos robustos que são menos sensíveis a eles, como árvores de decisão ou métodos baseados em ranking.'},\n",
    "    \n",
    "    {'front': 'O que é a técnica de redução de dimensionalidade PCA e como ela funciona?', \n",
    "     'back': 'PCA (Principal Component Analysis) é uma técnica de redução de dimensionalidade que transforma os dados em um conjunto menor de variáveis não correlacionadas chamadas componentes principais, preservando a maior parte da variância original dos dados.'},\n",
    "    \n",
    "    {'front': 'Descreva o que são redes neurais artificiais e como elas são usadas em Data Science.', \n",
    "     'back': 'Redes neurais artificiais são modelos de aprendizado de máquina inspirados no funcionamento do cérebro humano. Elas consistem em camadas de neurônios conectados que realizam operações matemáticas para aprender padrões complexos nos dados. Elas são usadas em uma ampla variedade de problemas em Data Science, desde reconhecimento de imagem até previsão de séries temporais.'},\n",
    "    \n",
    "    {'front': 'O que é o método de Monte Carlo e em que contexto ele é aplicado em Data Science?', \n",
    "     'back': 'O método de Monte Carlo é uma técnica de simulação estatística que utiliza amostras aleatórias para estimar resultados numéricos complexos. Ele é aplicado em Data Science para realizar análises de risco, otimização, integração numérica, entre outros.'},\n",
    "    \n",
    "    {'front': 'Como você avaliaria a importância das variáveis em um modelo de machine learning?', \n",
    "     'back': 'A importância das variáveis pode ser avaliada usando técnicas como análise de importância de variáveis, ganho de informação, coeficientes de modelo, ou através de métodos mais avançados como Permutation Importance ou SHAP (SHapley Additive exPlanations).'},\n",
    "    \n",
    "    {'front': 'O que é o método de otimização de hiperparâmetros e por que é importante?', \n",
    "     'back': 'O método de otimização de hiperparâmetros é usado para encontrar os melhores valores dos hiperparâmetros de um modelo de machine learning, maximizando sua performance. É importante porque os hiperparâmetros afetam diretamente o desempenho do modelo e podem ser difíceis de ajustar manualmente.'},\n",
    "    \n",
    "    {'front': 'Explique o conceito de aprendizado semi-supervisionado.', \n",
    "     'back': 'Aprendizado semi-supervisionado é uma abordagem híbrida que combina dados rotulados e não rotulados para treinar modelos de machine learning. Ele é útil quando há muitos dados não rotulados disponíveis, mas rotular esses dados manualmente seria custoso ou demorado.'},\n",
    "    \n",
    "    {'front': 'Como você lidaria com a heterogeneidade dos dados em um conjunto de dados grande e complexo?', \n",
    "     'back': 'A heterogeneidade dos dados pode ser tratada usando técnicas de pré-processamento de dados, normalização, seleção de características, agrupamento, ou usando modelos que são robustos a variações nos dados, como redes neurais profundas.'},\n",
    "    \n",
    "    {'front': 'O que é uma curva ROC e qual é a sua utilidade?', \n",
    "     'back': 'A curva ROC (Receiver Operating Characteristic) é uma curva que mostra a relação entre a taxa de verdadeiros positivos (sensibilidade) e a taxa de falsos positivos (especificidade) para diferentes limiares de classificação. É usada para avaliar o desempenho de um classificador binário em vários limiares e comparar diferentes modelos.'},\n",
    "    \n",
    "    {'front': 'Descreva o processo de feature engineering e sua importância em Data Science.', \n",
    "     'back': 'Feature engineering envolve a criação e seleção de variáveis (features) que são mais relevantes para um modelo de machine learning. Isso pode incluir transformações, criação de novas variáveis, seleção de características e redução de dimensionalidade. É importante porque variáveis bem escolhidas podem melhorar significativamente o desempenho do modelo.'},\n",
    "    \n",
    "    {'front': 'O que é o problema de sobreajuste (overfitting) e como você o detectaria em um modelo de machine learning?', \n",
    "     'back': 'Overfitting ocorre quando um modelo se ajusta muito bem aos dados de treinamento, mas não generaliza bem para novos dados. Pode ser detectado observando-se uma grande diferença entre o desempenho do modelo nos dados de treinamento e nos dados de teste, ou usando técnicas como validação cruzada.'}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tflearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
